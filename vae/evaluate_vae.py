# -*- coding: utf-8 -*-
"""evaluate_vae.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18Vg3gBJ8XFp-zHXxrwrfDDSKP8fx-sk1
"""

# Import required libraries
import random
import torch
import matplotlib.pyplot as plt
import torch.nn.functional as F
import numpy as np
from skimage.metrics import structural_similarity as ssim

# Tracks min, max, and mean values of tensors at different model stages
def track_tensor_values(model, dataloader, device):
    model.eval()
    dataset = dataloader.dataset
    
    # Select a random image from the dataset
    random_idx = random.randint(0, len(dataset) - 1)
    original_image = dataset[random_idx].to(device).unsqueeze(0)

    print("### Tensor Value Tracking ###")
    print(f"Input Image: Min: {original_image.min()}, Max: {original_image.max()}, Mean: {original_image.mean()}")

    with torch.no_grad():
        # Encoder forward pass
        enc1 = model.encoder.block1(original_image)
        print(f"Encoder Block 1 Output: Min: {enc1.min()}, Max: {enc1.max()}, Mean: {enc1.mean()}")

        enc2 = model.encoder.block2(enc1)
        print(f"Encoder Block 2 Output: Min: {enc2.min()}, Max: {enc2.max()}, Mean: {enc2.mean()}")

        enc3 = model.encoder.block3(enc2)
        print(f"Latent Space: Min: {enc3.min()}, Max: {enc3.max()}, Mean: {enc3.mean()}")

        # Decoder forward pass
        dec1 = model.decoder.block1(enc3)
        print(f"Decoder Block 1 Output: Min: {dec1.min()}, Max: {dec1.max()}, Mean: {dec1.mean()}")

        dec2 = model.decoder.block2(dec1)
        print(f"Decoder Block 2 Output: Min: {dec2.min()}, Max: {dec2.max()}, Mean: {dec2.mean()}")

        output_image = model.decoder.block3(dec2)
        print(f"Decoder Output: Min: {output_image.min()}, Max: {output_image.max()}, Mean: {output_image.mean()}")



# Visualizes a random input image and its reconstructed output
def visualize_random_input_output(model, dataloader, device):
    model.eval()
    dataset = dataloader.dataset
    
    # Select a random image from the dataset
    random_idx = random.randint(0, len(dataset) - 1)
    original_image = dataset[random_idx].to(device)

    with torch.no_grad():
        # Encode the input image and reconstruct it using the decoder
        _, _, latent, skips = model.encoder(original_image.unsqueeze(0))
        reconstructed_image = model.decoder(latent, skips).squeeze(0)

    # Undo normalization for visualization
    original_image = torch.clamp((original_image + 1) / 2.0, 0, 1)
    reconstructed_image = torch.clamp((reconstructed_image + 1) / 2.0, 0, 1)

    # Plot original and reconstructed images
    fig, axes = plt.subplots(1, 2, figsize=(12, 6))
    axes[0].imshow(original_image.permute(1, 2, 0).cpu().numpy())
    axes[0].set_title("Original Image")
    axes[0].axis("off")

    axes[1].imshow(reconstructed_image.permute(1, 2, 0).cpu().numpy())
    axes[1].set_title("Reconstructed Image")
    axes[1].axis("off")

    plt.tight_layout()
    plt.show()


def calculate_metrics(model, dataloader, device):
    """
    Evaluate the performance metrics of the VAE model:
    - MSE (Mean Squared Error)
    - SSIM (Structural Similarity Index)
    - PSNR (Peak Signal-to-Noise Ratio)
    """
    model.eval()
    mse_list = []
    ssim_list = []
    psnr_list = []

    with torch.no_grad():
        for data in dataloader:
            # Transfer original images to device
            original_image = data.to(device)

            # Reconstruct images using encoder and decoder (with skip connections)
            _, _, latent, skips = model.encoder(original_image)  # latent representation and skip connections
            reconstructed_image = model.decoder(latent, skips)  # pass along the skip connections

            # Normalize images (from [-1, 1] to [0, 1])
            original_image_norm = torch.clamp((original_image + 1) / 2.0, 0, 1)
            reconstructed_image_norm = torch.clamp((reconstructed_image + 1) / 2.0, 0, 1)

            # Compute pixel-wise MSE for the entire batch
            mse = F.mse_loss(reconstructed_image_norm, original_image_norm).item()
            mse_list.append(mse)

            # Convert images to numpy format
            original_np = original_image_norm.permute(0, 2, 3, 1).cpu().numpy()
            reconstructed_np = reconstructed_image_norm.permute(0, 2, 3, 1).cpu().numpy()

            # Calculate SSIM and PSNR for each image in the batch
            for i in range(original_np.shape[0]):
                ssim_value = ssim(
                    original_np[i],
                    reconstructed_np[i],
                    multichannel=True,
                    data_range=1.0,
                    win_size=3  # Smaller window size
                )
                psnr_value = 10 * np.log10(1 / mse)  # PSNR calculated based on MSE
                ssim_list.append(ssim_value)
                psnr_list.append(psnr_value)

    # Compute average metrics
    avg_mse = np.mean(mse_list)
    avg_ssim = np.mean(ssim_list)
    avg_psnr = np.mean(psnr_list)

    # All print operations are done within the function and the description text is in English.
    print(f"Mean Squared Error (MSE): {avg_mse:.4f}")
    print(f"Structural Similarity Index (SSIM): {avg_ssim:.4f}")
    print(f"Peak Signal-to-Noise Ratio (PSNR): {avg_psnr:.4f}")
    print("""
    1. MSE:   0.0 - 0.1 (Excellent),   0.1 - 0.5 (Good),   0.5 - 1.0 (Moderate),   1.0 - 2.0 (Poor),   >2.0 (Very Poor)
    2. SSIM:  0.9 - 1.0 (Excellent),   0.7 - 0.9 (Good),   0.5 - 0.7 (Moderate),   0.3 - 0.5 (Poor),   <0.3 (Very Poor)
    3. PSNR:  >30   (Excellent),   25 - 30   (Good),   20 - 25   (Moderate),   15 - 20   (Poor),   <15   (Very Poor)
    """)


# Plots training and validation losses at different stages
def plot_losses(all_losses):

    # 1) Train vs. validation loss per epoch
    plt.figure(figsize=(7,5))
    plt.plot(all_losses['train'], label="Train Loss (epoch)")
    plt.plot(all_losses['val'],   label="Val Loss (epoch)")
    plt.title("Epoch-based Train vs. Val Loss")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.show()

    # 2) Train reconstruction loss per step
    plt.figure(figsize=(7,5))
    plt.plot(all_losses['recon'], label="Train Recon (step)")
    plt.title("Step-based Train Reconstruction Loss")
    plt.xlabel("Train Step")
    plt.ylabel("Loss")
    plt.legend()
    plt.show()

    # 3) Validation loss components per step
    plt.figure(figsize=(7,5))
    plt.plot(all_losses['val'],      label="Val Total (step)")
    plt.plot(all_losses['val_kl'],   label="Val KL (step)")
    plt.plot(all_losses['val_recon'],label="Val Recon (step)")
    plt.title("Step-based Validation Loss Components")
    plt.xlabel("Validation Step")
    plt.ylabel("Loss")
    plt.legend()
    plt.show()

