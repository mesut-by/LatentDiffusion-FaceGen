# -*- coding: utf-8 -*-
"""model_vae.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yaI7r5cwZuYp1t9YUZucp14TtpgY1Nev
"""

import torch
import torch.nn as nn

from config import cfg

# Residual block with group normalization and SiLU activation
class ResidualBlock(nn.Module):
    def __init__(self, in_channels):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)
        self.gn1 = nn.GroupNorm(num_groups=cfg.num_groups, num_channels=in_channels)
        self.silu = nn.SiLU()
        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)
        self.gn2 = nn.GroupNorm(num_groups=cfg.num_groups, num_channels=in_channels)

    def forward(self, x):
        residual = x  # Preserve input for residual connection
        x = self.conv1(x)
        x = self.gn1(x)
        x = self.silu(x)
        x = self.conv2(x)
        x = self.gn2(x)
        return x + residual  # Add residual connection

# Attention block using channel-wise average and max pooling
class AttentionBlock(nn.Module):
    def __init__(self, kernel_size=7):
        super(AttentionBlock, self).__init__()
        self.conv = nn.Conv2d(2, 1, kernel_size, padding=(kernel_size - 1) // 2, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)  # Channel-wise average pooling
        max_out, _ = torch.max(x, dim=1, keepdim=True)  # Channel-wise max pooling
        combined = torch.cat([avg_out, max_out], dim=1)  # Concatenate along channel axis
        return x * self.sigmoid(self.conv(combined))  # Apply attention weighting

# Downsampling block with convolution, normalization, and activation
class Downsample(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):
        super(Downsample, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)
        self.norm = nn.GroupNorm(num_groups=min(cfg.num_groups, out_channels), num_channels=out_channels)
        self.silu = nn.SiLU()

    def forward(self, x):
        x = self.conv(x)
        x = self.norm(x)
        x = self.silu(x)
        return x


# Upsampling block using transposed convolution, normalization
class Upsample(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1):
        super(Upsample, self).__init__()
        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, output_padding)
        self.norm = nn.GroupNorm(num_groups=min(cfg.num_groups, out_channels), num_channels=out_channels)
        self.silu = nn.SiLU()

    def forward(self, x):
        x = self.conv_transpose(x)  # Transposed convolution for upsampling
        x = self.norm(x)  # Group normalization
        x = self.silu(x)  # SiLU activation
        return x


# Encoder 
class Encoder(nn.Module):
    def __init__(self, in_channels=cfg.in_channels, latent_channels=cfg.latent_channels):
        super(Encoder, self).__init__()

        self.block1 = nn.Sequential(
            Downsample(in_channels, 64),
            ResidualBlock(64),
            AttentionBlock(),
            ResidualBlock(64),
        )

        self.block2 = nn.Sequential(
            Downsample(64, 128),
            ResidualBlock(128),
            AttentionBlock()
        )

        self.block3 = nn.Sequential(
            Downsample(128, latent_channels),
            ResidualBlock(latent_channels),
            ResidualBlock(latent_channels)
        )

        self.block4 = nn.Sequential(
            nn.Conv2d(latent_channels, latent_channels * 2, kernel_size=1),  # Channel expansion
            ResidualBlock(latent_channels * 2)
        )

    def forward(self, x):
        skip1 = self.block1(x)   # Feature extraction at high resolution
        skip2 = self.block2(skip1)  # Further compression
        skip3 = self.block3(skip2)  # Deeper latent representation
        x = self.block4(skip3)  # Final transformation in latent space

        # Compute mean and log variance for latent representation
        mean, log_variance = torch.chunk(x, 2, dim=1)
        log_variance = torch.clamp(log_variance, -20, 20)  
        variance = log_variance.exp()
        stdev = variance.sqrt()

        # Sample from the latent distribution
        noise = torch.randn_like(mean)
        sampled = mean + stdev * noise

        return mean, log_variance, sampled, [skip1, skip2, skip3]  # Skip connections for decoder


# Decoder 
class Decoder(nn.Module):
    def __init__(self, use_skip=True, latent_channels=cfg.latent_channels, out_channels=cfg.out_channels):
        super(Decoder, self).__init__()
        self.use_skip = use_skip

        self.block1 = nn.Sequential(
            Upsample(latent_channels, 128),
            ResidualBlock(128),
            ResidualBlock(128)
        )

        self.block2 = nn.Sequential(
            Upsample(128, 64),
            ResidualBlock(64),
            AttentionBlock(),
            ResidualBlock(64)
        )

        self.block3 = nn.Sequential(
            Upsample(64, out_channels),
            nn.Tanh()  # Output normalized to [-1, 1]
        )

    def forward(self, x, skips):
        if self.use_skip:
            skip1, skip2, skip3 = skips  # Retrieve skip connections
            x = self.block1(x + skip3)  # Add skip3 for better feature retention
            x = self.block2(x + skip2)  # Add skip2 for mid-level details
            x = self.block3(x + skip1)  # Add skip1 for fine details
        else:
            x = self.block1(x)  # Decode without skip connections
            x = self.block2(x)
            x = self.block3(x)
        
        return x  # Return reconstructed output

# VAE 
class VAE(nn.Module):
    def __init__(self, in_channels=cfg.in_channels, latent_channels=cfg.latent_channels, 
                 out_channels=cfg.out_channels, use_skip=True):
        super(VAE, self).__init__()
        self.encoder = Encoder(in_channels, latent_channels)
        self.decoder = Decoder(use_skip=use_skip, latent_channels=latent_channels, out_channels=out_channels)

    def forward(self, x):
        mean, log_variance, sampled, skips = self.encoder(x)  # Encode input
        reconstructed = self.decoder(sampled, skips)  # Decode from latent space
        return mean, log_variance, reconstructed  # Return all relevant outputs
